{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QeyU-01RjVU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# üîß XGBoost Hyperparameter Tuning using RandomizedSearchCV\n",
        "# =====================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# --- 1Ô∏è‚É£ Load data ---\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# --- 2Ô∏è‚É£ Feature Engineering ---\n",
        "train_df['BMI'] = train_df['Weight'] / ((train_df['Height'] / 100.0) ** 2)\n",
        "test_df['BMI'] = test_df['Weight'] / ((test_df['Height'] / 100.0) ** 2)\n",
        "\n",
        "# --- 3Ô∏è‚É£ Target and feature separation ---\n",
        "target = \"WeightCategory\"\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train_df[target])\n",
        "X = train_df.drop(columns=['id', target], errors='ignore')\n",
        "\n",
        "# --- 4Ô∏è‚É£ Handle categorical features (One-hot encoding) ---\n",
        "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "# --- 5Ô∏è‚É£ Scale numeric features ---\n",
        "num_cols = ['Height', 'Weight', 'BMI']\n",
        "scaler = StandardScaler()\n",
        "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(le.classes_),\n",
        "    tree_method='hist',\n",
        "    eval_metric='mlogloss',\n",
        "    seed=38,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "\n",
        "param_distributions = {\n",
        "    'learning_rate': uniform(0.03, 0.04),       # around 0.05 ‚Üí 0.03‚Äì0.07\n",
        "    'max_depth': randint(5, 8),                 # around 6 ‚Üí 5, 6, 7\n",
        "    'min_child_weight': randint(2, 5),          # around 3 ‚Üí 2‚Äì4\n",
        "    'subsample': uniform(0.8, 0.2),             # around 0.9 ‚Üí 0.8‚Äì1.0\n",
        "    'colsample_bytree': uniform(0.8, 0.2),      # around 0.9 ‚Üí 0.8‚Äì1.0\n",
        "    'gamma': uniform(0.05, 0.1)                 # around 0.1 ‚Üí 0.05‚Äì0.15\n",
        "}\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=30,                 # number of random combinations to test\n",
        "    scoring='f1_macro',        # scoring metric\n",
        "    cv=3,                      # 3-fold cross-validation\n",
        "    verbose=2,                 # print progress\n",
        "    random_state=38,\n",
        "    n_jobs=-1                  # use all CPU cores\n",
        ")\n",
        "\n",
        "print(\"\\nüîé Starting RandomizedSearchCV tuning...\\n\")\n",
        "random_search.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"\\n‚úÖ Best Parameters Found:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "print(f\"\\nüèÜ Best F1-macro Score: {random_search.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': len(le.classes_),\n",
        "    'tree_method': 'hist',\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'seed': 38,\n",
        "    **random_search.best_params_\n",
        "}\n",
        "\n",
        "print(\"\\nüîß Final tuned xgb_params to use in training:\")\n",
        "print(xgb_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efXAeoN-DlMZ",
        "outputId": "92cf4068-2919-4d32-8f77-9bfde893fda5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé Starting RandomizedSearchCV tuning...\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:40:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Best Parameters Found:\n",
            "{'colsample_bytree': np.float64(0.8510679370361254), 'gamma': np.float64(0.08299983049123688), 'learning_rate': np.float64(0.06665234059545111), 'max_depth': 7, 'min_child_weight': 4, 'subsample': np.float64(0.8172742477700612)}\n",
            "\n",
            "üèÜ Best F1-macro Score: 0.8913\n",
            "\n",
            "üîß Final tuned xgb_params to use in training:\n",
            "{'objective': 'multi:softprob', 'num_class': 7, 'tree_method': 'hist', 'eval_metric': 'mlogloss', 'seed': 38, 'colsample_bytree': np.float64(0.8510679370361254), 'gamma': np.float64(0.08299983049123688), 'learning_rate': np.float64(0.06665234059545111), 'max_depth': 7, 'min_child_weight': 4, 'subsample': np.float64(0.8172742477700612)}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}